{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "from toolboxes import Configurator, AnkiCommunicator, AnkiCardWriter\n",
    "from toolboxes import StackOrganizer\n",
    "from ExerciseWriter import ExerciseWriter\n",
    "from Exercise import ExerciseFactory\n",
    "from VocabNotes import VocabNotes\n",
    "import pyperclip\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "\n",
    "def copy_folder(source_folder, destination_folder) -> None:\n",
    "    destination_path = Path(destination_folder)\n",
    "    source_path = Path(source_folder)\n",
    "    if not destination_path.exists():\n",
    "        shutil.copytree(source_path, destination_path)\n",
    "\n",
    "with open('../src/paths.json') as f:\n",
    "    paths = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "date = 20010101\n",
    "\n",
    "\n",
    "# Make a new folder\n",
    "template_folder = '../src/resources/Templates'\n",
    "export_folder = f'./Exports/{date}'\n",
    "copy_folder(template_folder, export_folder)\n",
    "\n",
    "# Paths of the templates\n",
    "def_template_path = '/Definition/template.tex'\n",
    "collocation_template_path = '/Collocation/template.tex'\n",
    "reading_template_path = '/Reading/template.tex'\n",
    "gap_filling_template_path = '/Fill-in-the-gap/template.tex'\n",
    "translation_template_path = '/Translation/template.tex'\n",
    "comprehension_template_path = '/Comprehension/template.tex'\n",
    "spelling_template_path = '/Spelling/template.tex'\n",
    "correction_template_path = '/Correction/template.tex'\n",
    "\n",
    "# Paths of the output folder\n",
    "def_output_folder = export_folder + '/Definition'\n",
    "collocation_output_folder = export_folder + '/Collocation'\n",
    "reading_output_folder = export_folder + '/Reading'\n",
    "gap_filling_output_folder = export_folder + '/Fill-in-the-gap'\n",
    "translation_output_folder = export_folder + '/Translation'\n",
    "spelling_output_folder = export_folder + '/Spelling'\n",
    "correction_output_folder = export_folder + '/Correction'\n",
    "\n",
    "# Creation of writers\n",
    "factory = ExerciseFactory()\n",
    "def_writer = ExerciseWriter(template_path=def_template_path, output_folder=def_output_folder)\n",
    "collocation_writer = ExerciseWriter(template_path=collocation_template_path, output_folder=collocation_output_folder)\n",
    "reading_exercise_writer = ExerciseWriter(template_path=reading_template_path, output_folder=reading_output_folder)\n",
    "gap_filling_exercise_writer = ExerciseWriter(template_path=gap_filling_template_path, output_folder=gap_filling_output_folder)\n",
    "translation_exercise_writer = ExerciseWriter(template_path=translation_template_path, output_folder=translation_output_folder)\n",
    "spelling_exercise_writer = ExerciseWriter(template_path=spelling_template_path, output_folder=spelling_output_folder)\n",
    "correction_exercise_writer = ExerciseWriter(template_path=correction_template_path, output_folder=correction_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration for `Vocab Explorer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to Anki and import the cards from the file Anki Cards.csv\n",
      "\n",
      "Number of new words: 10;\n",
      "Number of old words: 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = 'Vocab Builder'\n",
    "num_of_words_to_learn = 10\n",
    "\n",
    "# Fetch unlearned words\n",
    "configurator = Configurator(json_path=paths[category]['schedule'])\n",
    "tomorrow_new = configurator.get_n_words_to_learn(num_of_words_to_learn)\n",
    "with open(paths[category]['cards']) as f:\n",
    "    whole_stack = json.load(f)\n",
    "new_stack = {card_id: whole_stack[card_id] for card_id in tomorrow_new}\n",
    "writer = AnkiCardWriter(new_stack)\n",
    "Path(f'Exports/{date}_{category}').mkdir(parents=True, exist_ok=True)\n",
    "writer.write_cards(f'Exports/{date}_{category}/Anki Cards.csv')\n",
    "print('Go to Anki and import the cards from the file Anki Cards.csv')\n",
    "configurator.study_n_words(num_of_words_to_learn)\n",
    "\n",
    "# Fetch learned words\n",
    "anki = AnkiCommunicator()\n",
    "tomorrow_review = anki.get_words_for_tomorrow(deck_name=category)\n",
    "review_stack = {card_id: whole_stack[card_id] for card_id in tomorrow_review}\n",
    "# combine the new and review stacks\n",
    "tomorrow_stack = {**new_stack, **review_stack}\n",
    "print(f'''\n",
    "Number of new words: {len(tomorrow_new)};\n",
    "Number of old words: {len(tomorrow_review)}.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration for `Everyday English`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Everyday English'\n",
    "num_of_words_to_learn = 0\n",
    "\n",
    "# Fetch unlearned words\n",
    "configurator = Configurator(json_path=paths[category]['schedule'])\n",
    "tomorrow_new = configurator.get_n_words_to_learn(num_of_words_to_learn)\n",
    "with open(paths[category]['stack']) as f:\n",
    "    whole_stack = json.load(f)\n",
    "new_stack = {card_id: whole_stack[card_id] for card_id in tomorrow_new}\n",
    "writer = AnkiCardWriter(new_stack)\n",
    "Path(f'Exports/{date}_{category}').mkdir(parents=True, exist_ok=True)\n",
    "writer.write_cards(f'Exports/{date}_{category}/Anki Cards.csv')\n",
    "print('Go to Anki and import the cards from the file Anki Cards.csv')\n",
    "configurator.study_n_words(num_of_words_to_learn)\n",
    "\n",
    "# Fetch learned words\n",
    "anki = AnkiCommunicator()\n",
    "tomorrow_review = anki.get_words_for_tomorrow(deck_name=category)\n",
    "# tomorrow_review = anki.get_words_for_today(deck_name=category)\n",
    "review_stack = {card_id: whole_stack[card_id] for card_id in tomorrow_review}\n",
    "print(f'''\n",
    "Number of new words: {len(tomorrow_new)};\n",
    "Number of old words: {len(tomorrow_review)}.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the word list and the set index here and get the prompt to create definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_start_idx = 1\n",
    "def_end_idx = 10\n",
    "def_set_index = 1\n",
    "\n",
    "\n",
    "cropped_list = tomorrow_new[def_start_idx-1:def_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_notes = StackOrganizer(stack=cropped_stack)\n",
    "input_stack = stack_organizer_for_notes.reorganize()\n",
    "\n",
    "vocab_notes = VocabNotes(word_entries=input_stack)\n",
    "def_writer.render_template(exercise=vocab_notes, set_index=def_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill in the gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the word list here and get the prompt to create example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_filling_start_idx = 1\n",
    "gap_filling_end_idx = 10\n",
    "gap_filling_set_index = 1\n",
    "\n",
    "cropped_list = tomorrow_new[gap_filling_start_idx-1:gap_filling_end_idx]\n",
    "# cropped_list = tomorrow_review[gap_filling_start_idx-1:gap_filling_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_gap_filling = StackOrganizer(stack=cropped_stack, only_single_word=True)\n",
    "input_stack = stack_organizer_for_gap_filling.reorganize()\n",
    "gap_filling_exercise = factory.create_exercise(exercise_type='Fill in the gap', word_entries=input_stack)\n",
    "gap_filling_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste the example sentences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_filling_sentences = pyperclip.paste()\n",
    "gap_filling_exercise.generate_exercise(text=gap_filling_sentences)\n",
    "gap_filling_exercise_writer.render_template(exercise=gap_filling_exercise, set_index=gap_filling_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentence Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter the set index and the word list here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_start_idx = 1\n",
    "correction_end_idx = 10\n",
    "correction_set_index = 1\n",
    "\n",
    "cropped_list = tomorrow_new[correction_start_idx-1:correction_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_correction = StackOrganizer(stack=cropped_stack)\n",
    "input_stack = stack_organizer_for_correction.reorganize()\n",
    "correction_exercise = factory.create_exercise(exercise_type='Correction', word_entries=input_stack)\n",
    "correction_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste the exercise here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_sentences = pyperclip.paste()\n",
    "correction_exercise.generate_exercise(text=correction_sentences)\n",
    "correction_exercise_writer.render_template(exercise=correction_exercise, set_index=correction_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiple Choice - Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_start_idx = 1\n",
    "collocation_end_idx = 10\n",
    "collocation_set_index = 1\n",
    "\n",
    "\n",
    "cropped_list = tomorrow_new[collocation_start_idx-1:collocation_end_idx]\n",
    "# cropped_list = tomorrow_review[collocation_start_idx-1:collocation_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_collocation = StackOrganizer(stack=cropped_stack)\n",
    "input_stack = stack_organizer_for_collocation.reorganize()\n",
    "\n",
    "collocation_exercise = factory.create_exercise(exercise_type='Collocation multiple choice', word_entries=input_stack)\n",
    "collocation_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to Exports/20010101/Collocation/output_1.tex\n"
     ]
    }
   ],
   "source": [
    "collocation_exercise_text = pyperclip.paste()\n",
    "collocation_exercise.generate_exercise(text=collocation_exercise_text)\n",
    "collocation_writer.render_template(exercise=collocation_exercise, set_index=collocation_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multiple Choice - Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_start_idx = 1\n",
    "spelling_end_idx = 10\n",
    "spelling_set_index = 1\n",
    "\n",
    "cropped_list = tomorrow_new[spelling_start_idx-1:spelling_end_idx]\n",
    "# cropped_list = tomorrow_review[spelling_start_idx-1:spelling_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_spelling = StackOrganizer(stack=cropped_stack, only_single_word=True)\n",
    "input_stack = stack_organizer_for_spelling.reorganize()\n",
    "\n",
    "spelling_exercise = factory.create_exercise(exercise_type='Spelling multiple choice', word_entries=input_stack)\n",
    "spelling_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_exercise_text = pyperclip.paste()\n",
    "spelling_exercise.generate_exercise(text=spelling_exercise_text)\n",
    "spelling_exercise_writer.render_template(exercise=spelling_exercise, set_index=spelling_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_start_idx = 1\n",
    "translation_end_idx = 10\n",
    "translation_set_index = 1\n",
    "\n",
    "cropped_list = tomorrow_new[translation_start_idx-1:translation_end_idx]\n",
    "# cropped_list = tomorrow_review[translation_start_idx-1:translation_end_idx]\n",
    "cropped_stack = dict()\n",
    "for card_id in cropped_list:\n",
    "    cropped_stack[card_id] = tomorrow_stack[card_id]\n",
    "stack_organizer_for_translation = StackOrganizer(stack=cropped_stack)\n",
    "input_stack = stack_organizer_for_translation.reorganize()\n",
    "translation_exercise = factory.create_exercise(exercise_type='Translation', word_entries=input_stack)\n",
    "translation_exercise.generate_exercise()\n",
    "translation_exercise_writer.render_template(exercise=translation_exercise, set_index=translation_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter the set index and the word list here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_start_idx = 1\n",
    "reading_end_idx = 10\n",
    "reading_set_index = 1\n",
    "reading_word_list = tomorrow_review[reading_start_idx-1:reading_end_idx]\n",
    "reading_exercise = factory.create_exercise(exercise_type='Reading', word_entries={term: tomorrow_review_with_def[term] for term in reading_word_list})\n",
    "reading_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste the passages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = pyperclip.paste()\n",
    "reading_exercise.import_passage(text=passages)\n",
    "reading_exercise.get_second_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paste the cloze exercise here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_exercise_text = pyperclip.paste()\n",
    "\n",
    "reading_exercise.import_exercise(text=cloze_exercise_text)\n",
    "reading_exercise.finish_import()\n",
    "reading_gatherer.import_exercise(exercise=reading_exercise)\n",
    "reading_exercise_writer.render_template(set_index=reading_set_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter the set index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_start_idx = 6\n",
    "dialogue_end_idx = 11\n",
    "dialogue_set_index = 2\n",
    "\n",
    "# dialogue_word_list = tomorrow_new[dialogue_start_idx-1:dialogue_end_idx]\n",
    "# dialogue_word_entries = {term: tomorrow_new_with_def[term] for term in dialogue_word_list}\n",
    "\n",
    "dialogue_word_list = tomorrow_review[dialogue_start_idx-1:dialogue_end_idx]\n",
    "dialogue_word_entries = {term: tomorrow_review_with_def[term] for term in dialogue_word_list}\n",
    "\n",
    "dialogue_exercise = factory.create_exercise(exercise_type='Dialogue', word_entries={term: dialogue_word_entries[term] for term in dialogue_word_list})\n",
    "dialogue_exercise.get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_dict_text = pyperclip.paste()\n",
    "dialogue_dict = json.loads(dialogue_dict_text)\n",
    "dialogue_exercise.generate_exercise(dialogue_dict=dialogue_dict)\n",
    "dialogue_exercise.finish_import()\n",
    "dialogue_gatherer.import_exercise(exercise=dialogue_exercise)\n",
    "dialogue_exercise_writer.render_template(set_index=dialogue_set_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
